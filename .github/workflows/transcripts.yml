name: Pull YouTube transcripts (2s pause, tvhtml5 client, preflight, giant txt)

on:
  workflow_dispatch:
  schedule:
    - cron: "17 3 * * *"

jobs:
  run:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    env:
      PLAYLIST_URL: "https://www.youtube.com/playlist?list=PLstjectj9BFgWGjHn4y2oygN34oFpSPjR"
      TEST_VIDEO_ID: "dQw4w9WgXcQ"  # cookie sanity check

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: true

      - name: Set up Python + deps
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: |
          python -m pip install --upgrade pip
          pip install 'yt-dlp[default]'

      - name: Restore cookies.txt (must be fresh)
        run: |
          if [ -n "${{ secrets.YT_COOKIES_B64 }}" ]; then
            printf "%s" "${{ secrets.YT_COOKIES_B64 }}" | base64 -d > cookies.txt
            echo "cookies.txt restored (head):"
            head -n 5 cookies.txt || true
            if ! grep -E "youtube\.com" cookies.txt >/dev/null 2>&1; then
              echo "WARNING: cookies.txt has no youtube.com entries"
            fi
          else
            echo "No YT_COOKIES_B64 secret set; yt-dlp may be blocked."
          fi

      - name: Preflight cookies (tvhtml5, expect EN auto-sub)
        run: |
          echo "==> Testing cookies on $TEST_VIDEO_ID via tvhtml5…"
          set -o pipefail
          yt-dlp --cookies cookies.txt --skip-download --write-auto-sub --sub-langs en --sub-format vtt \
                 --extractor-args "youtube:player_client=tvhtml5" \
                 -o "preflight.vtt" "https://www.youtube.com/watch?v=$TEST_VIDEO_ID" 2>&1 | tee preflight.log || true
          if grep -q "Sign in to confirm you’re not a bot" preflight.log || grep -Eq "HTTP Error (429|403)" preflight.log; then
            echo "ERROR: Cookies appear invalid/blocked. Refresh YT_COOKIES_B64."
            exit 1
          fi
          echo "Preflight completed (note: this video may lack EN subs; that’s OK for cookie validation)."

      - name: Download English subtitles (tvhtml5, 2s between videos)
        run: |
          mkdir -p transcripts
          COOKIES_ARG=""
          [ -f cookies.txt ] && COOKIES_ARG="--cookies cookies.txt"

          echo "==> Using player_client=tvhtml5 with 2s between videos"
          yt-dlp \
            $COOKIES_ARG \
            --ignore-errors \
            --yes-playlist \
            --skip-download \
            --write-sub --write-auto-sub \
            --sub-langs "en,en-US,en-GB" \
            --sub-format vtt \
            --extractor-args "youtube:player_client=tvhtml5" \
            --sleep-interval 2 \
            --max-sleep-interval 2 \
            --retries 5 \
            --limit-rate 120K \
            --throttled-rate 120K \
            --output "transcripts/%(title)s [%(id)s].%(ext)s" \
            "${PLAYLIST_URL}" || true

      - name: Ensure we actually downloaded subtitles
        run: |
          count=$(ls -1 transcripts/*.vtt 2>/dev/null | wc -l | tr -d ' ')
          echo "Found $count .vtt files."
          if [ "$count" = "0" ]; then
            echo "ERROR: No subtitles were downloaded. Likely PO-token issue if using web client, or cookies stale."
            echo "       We are using tvhtml5 here; if still zero, refresh cookies or try again later."
            exit 1
          fi

      - name: Build ALL_TRANSCRIPTS.txt (clean tags, de-dupe across blanks)
        run: |
          python - <<'PY'
          import glob, os, re
          from collections import deque
          from pathlib import Path

          RE_HEADER = re.compile(r'^(WEBVTT|Kind:|Language:)\b', re.I)
          RE_CUE    = re.compile(r'^\d{2}:\d{2}:\d{2}\.\d{3}\s+-->\s+\d{2}:\d{2}:\d{2}\.\d{3}')
          RE_INLINE = re.compile(r'<(?:\d{2}:\d{2}:\d{2}\.\d{3}|/?c(?:\.[^>]*)?)>')  # <00:..> and <c.*> tags

          def clean_line(s: str) -> str:
              s = RE_INLINE.sub('', s)
              s = re.sub(r'^\[[^\]]+\]$', '', s).strip()  # drop [Music], etc.
              s = re.sub(r'[ \t]+', ' ', s).strip()
              return s

          def vtt_to_txt(path: str) -> str:
              out = []
              last_nonempty = deque(maxlen=3)  # kill karaoke repeats even across a blank
              pending_blank = False
              with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                  for raw in f:
                      s = raw.rstrip('\n')
                      if RE_HEADER.match(s) or RE_CUE.match(s):
                          continue
                      if re.fullmatch(r'\d+', s.strip()):
                          continue
                      s = clean_line(s)
                      if not s:
                          pending_blank = True
                          continue
                      if s in last_nonempty:
                          pending_blank = False
                          continue
                      if pending_blank and out and out[-1] != '':
                          out.append('')
                      pending_blank = False
                      out.append(s)
                      last_nonempty.append(s)
              txt = '\n'.join(out).strip()
              txt = re.sub(r'\n{3,}', '\n\n', txt)
              return txt

          Path('transcripts').mkdir(exist_ok=True)
          all_sections = []
          vtts = glob.glob('transcripts/*.vtt')

          def key_fn(p):
              base = os.path.basename(p)
              m = re.match(r'^(?P<title>.+) \[(?P<id>[-\\w]{6,})\](?:\\.(?P<lang>[\\w-]+))?\\.vtt$', base)
              title = (m.group('title') if m else base).lower()
              vid = (m.group('id') if m else '')
              return (title, vid)
          vtts.sort(key=key_fn)

          for vtt in vtts:
              base = os.path.basename(vtt)
              m = re.match(r'^(?P<title>.+) \[(?P<id>[-\\w]{6,})\](?:\\.(?P<lang>[\\w-]+))?\\.vtt$', base)
              if not m:
                  continue
              title = m.group('title'); vid = m.group('id')
              url = f'https://www.youtube.com/watch?v={vid}'
              text = vtt_to_txt(vtt)
              (Path('transcripts') / f'{title} [{vid}].txt').write_text(text, encoding='utf-8')
              header = ["######", f"Video ID: {vid}", f"URL: {url}", f"Title: {title}", "Transcript:"]
              all_sections.append('\n'.join(header) + '\n' + (text.strip() if text else '') + '\n')

          Path("ALL_TRANSCRIPTS.txt").write_text('\n'.join(all_sections).strip() + '\n', encoding='utf-8')
          print("Wrote ALL_TRANSCRIPTS.txt with", len(all_sections), "sections.")
          PY

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: transcripts
          path: |
            transcripts/*.vtt
            transcripts/*.txt
            ALL_TRANSCRIPTS.txt
          if-no-files-found: warn

      - name: Commit results
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add ALL_TRANSCRIPTS.txt || true
          [ -d transcripts ] && git add transcripts/* || true
          git status
          git commit -m "Update transcripts (ALL_TRANSCRIPTS.txt + cleaned per-video .txt)" || echo "No changes"
          git push
